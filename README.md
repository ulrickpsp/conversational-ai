# ğŸ—£ï¸ Multi-Agent AI Debate

A real-time debate platform where **16 AI agents with distinct roles** argue, challenge, and build on each other's ideas â€” sequentially, turn by turn. Built with Next.js, Server-Sent Events, Perplexity's web-search API, and 15 free OpenRouter models.

![Next.js](https://img.shields.io/badge/Next.js-16-black?logo=next.js)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?logo=typescript)
![Tailwind CSS](https://img.shields.io/badge/TailwindCSS-4-38bdf8?logo=tailwindcss)

---

## âœ¨ Features

- **16 unique agents** debating one at a time in sequential round-robin
- **Role-based prompts** â€” each agent has a distinct perspective (Critic, Architect, Economist, Skeptic, Provocateurâ€¦) to eliminate repetition
- **Real-time streaming** via Server-Sent Events (SSE)
- **Perplexity integration** with live web search for up-to-date facts
- **Pause & resume** mid-debate: inject your own comments and have agents pick up with that context
- **Scroll freely** while agents write â€” auto-scroll only kicks in when you're at the bottom
- **Persistent state** â€” F5 / page refresh restores the full conversation from localStorage
- **Error resilience** â€” agents that fail (rate limit, 404) are silently skipped
- **Debate modes**: Conservative Â· Balanced Â· Aggressive
- **Conclusion synthesis** â€” stop at any time to generate a structured JSON conclusion

---

## ğŸ¤– The 16 Agents

| # | Agent | Model | Role |
|---|-------|-------|------|
| 1 | ğŸŒ Perplexity | `sonar-reasoning-pro` | **Researcher** â€” real-time web data |
| 2 | ğŸ§  Qwen3 235B | `qwen3-235b-a22b-thinking-2507` | **Critic** â€” devil's advocate |
| 3 | ğŸ’š GPT-OSS 120B | `gpt-oss-120b:free` | **Architect** â€” system design |
| 4 | ğŸ¦™ Llama 70B | `llama-3.3-70b-instruct:free` | **Risk Manager** â€” what can go wrong |
| 5 | ğŸ’  Gemma 27B | `gemma-3-27b-it:free` | **Economist** â€” financial viability |
| 6 | ğŸ‘ï¸ Qwen3 VL 235B | `qwen3-vl-235b-a22b-thinking` | **Visionary** â€” disruptive ideas |
| 7 | ğŸŸ¢ Nemotron 30B | `nemotron-3-nano-30b-a3b:free` | **Engineer** â€” concrete implementation |
| 8 | ğŸ”¸ Trinity Mini | `trinity-mini:free` | **Simplifier** â€” cut through noise |
| 9 | ğŸ–¼ï¸ Nemotron 12B | `nemotron-nano-12b-v2-vl:free` | **Validator** â€” detect contradictions |
| 10 | ğŸš€ Step 3.5 | `step-3.5-flash:free` | **Strategist** â€” macro vision |
| 11 | ğŸ® GLM 4.5 | `glm-4.5-air:free` | **Historian** â€” precedents & cases |
| 12 | â˜€ï¸ Solar Pro 3 | `solar-pro-3:free` | **Optimizer** â€” efficiency & cuts |
| 13 | âš¡ Nemotron 9B | `nemotron-nano-9b-v2:free` | **Skeptic** â€” demands proof |
| 14 | ğŸ’™ GPT-OSS 20B | `gpt-oss-20b:free` | **Pragmatist** â€” what actually works |
| 15 | ğŸ”º Trinity Large | `trinity-large-preview:free` | **Integrator** â€” synthesizes views |
| 16 | ğŸ’§ Liquid 1.2B | `lfm-2.5-1.2b-thinking:free` | **Provocateur** â€” uncomfortable questions |

---

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx              # Main UI
â”‚   â”œâ”€â”€ globals.css
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ debate/
â”‚           â”œâ”€â”€ route.ts      # SSE streaming endpoint
â”‚           â””â”€â”€ conclude/
â”‚               â””â”€â”€ route.ts  # Conclusion synthesis endpoint
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatView.tsx          # Message feed with smart scroll
â”‚   â”œâ”€â”€ StatusBar.tsx         # Running state, pause/resume UI
â”‚   â”œâ”€â”€ ProposalForm.tsx      # Input form
â”‚   â””â”€â”€ ConclusionPanel.tsx   # Final synthesis display
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useDebateStream.ts    # SSE client + localStorage persistence
â””â”€â”€ lib/
    â”œâ”€â”€ models.ts             # Agent definitions + roles
    â”œâ”€â”€ orchestrator.ts       # Sequential round-robin engine
    â”œâ”€â”€ prompts.ts            # Role-specific system prompts
    â”œâ”€â”€ perplexity.ts         # Perplexity API client
    â”œâ”€â”€ openrouter.ts         # OpenRouter API client
    â”œâ”€â”€ config.ts             # Token limits, settings
    â””â”€â”€ types.ts              # Shared TypeScript types
```

**Flow:**
1. User submits a proposal
2. Server opens an SSE stream
3. Orchestrator iterates agents round-robin, calling each API sequentially
4. Tokens stream back to the client in real time
5. Each agent sees the full conversation history and responds from its role
6. User can pause, inject a comment, and resume â€” agents continue with that context

---

## ğŸš€ Getting Started

### Prerequisites

- Node.js 20+
- A [Perplexity API key](https://www.perplexity.ai/settings/api) (paid, ~$0.001/request)
- An [OpenRouter API key](https://openrouter.ai/settings/keys) (free tier â€” all 15 OpenRouter models cost $0)

### Installation

```bash
git clone https://github.com/ulrickpsp/conversational-ai.git
cd conversational-ai
npm install
```

### Environment Setup

```bash
cp .env.local.example .env.local
```

Edit `.env.local` and add your keys:

```env
PERPLEXITY_API_KEY=pplx-your-key-here
OPENROUTER_API_KEY=sk-or-v1-your-key-here
```

### Run

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000).

---

## ğŸ® Usage

1. **Enter a proposal** â€” a question, idea, or topic you want debated
2. **Choose a mode**: Conservative / Balanced / Aggressive
3. **Watch 16 agents** argue in sequence, each from their unique role
4. **Scroll freely** â€” auto-scroll pauses when you scroll up, resumes at the bottom
5. **Pause anytime** â€” click â¸ to pause, write a steering comment, then â–¶ï¸ Continue
6. **Stop & conclude** â€” click â¹ to generate a structured JSON conclusion
7. **Refresh safely** â€” F5 restores the full conversation from localStorage
8. **New session** â€” click ğŸ”„ to clear everything and start fresh

---

## âš™ï¸ Configuration

Key settings in `src/lib/config.ts`:

| Setting | Default | Description |
|---------|---------|-------------|
| `maxTokensPerplexity` | `400` | Max tokens per Perplexity turn |
| `maxTokensOpenRouter` | `500` | Max tokens per OpenRouter turn |

---

## ğŸ› ï¸ Tech Stack

- **[Next.js 16](https://nextjs.org/)** â€” App Router, Turbopack
- **[React 19](https://react.dev/)** â€” UI
- **[TypeScript 5](https://www.typescriptlang.org/)** â€” Type safety
- **[Tailwind CSS 4](https://tailwindcss.com/)** â€” Styling
- **[OpenAI SDK v6](https://github.com/openai/openai-node)** â€” Compatible interface for Perplexity + OpenRouter
- **Server-Sent Events** â€” Real-time token streaming
- **localStorage** â€” Client-side debate persistence

---

## ğŸ”’ Security

- API keys are stored server-side only in `.env.local`
- `.env.local` is gitignored â€” never committed
- Keys are never exposed to the browser
- All API calls happen in Next.js Route Handlers (server-side)

---

## ğŸ“„ License

MIT
