# ğŸ—£ï¸ Multi-Agent AI Debate

A real-time debate platform where **16 AI agents with distinct roles** argue, challenge, and build on each other's ideas â€” sequentially, turn by turn. Built with Next.js, Server-Sent Events, Perplexity's web-search API, and 15 free OpenRouter models.

![Next.js](https://img.shields.io/badge/Next.js-16-black?logo=next.js)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?logo=typescript)
![Tailwind CSS](https://img.shields.io/badge/TailwindCSS-4-38bdf8?logo=tailwindcss)

---

## âœ¨ Features

- **16 unique roles** debating in sequential order with **resilient model fallback**
- **Dynamic role-model rotation** â€” if a model fails (rate limit, 404, API error), the role automatically tries the next available model
- **Role-based prompts** â€” each role has a distinct perspective (Critic, Architect, Economist, Skeptic, Provocateurâ€¦) to eliminate repetition
- **Real-time streaming** via Server-Sent Events (SSE)
- **Perplexity integration** with live web search for up-to-date facts
- **Pause & resume** mid-debate: inject your own comments and have agents pick up with that context
- **Scroll freely** while agents write â€” auto-scroll only kicks in when you're at the bottom
- **Persistent state** â€” F5 / page refresh restores the full conversation from localStorage
- **Error resilience** â€” agents that fail (rate limit, 404) are silently retried with alternative models
- **Debate modes**: Conservative Â· Balanced Â· Aggressive
- **Conclusion synthesis** â€” stop at any time to generate a structured JSON conclusion

---

## ğŸ“¸ Screenshots

### Proposal Form
![Proposal Form](docs/screenshots/01-proposal-form.png)
*Enter your proposal and configure debate mode*

### Active Debate
![Active Debate](docs/screenshots/02-active-debate.png)
*16 agents debating sequentially with real-time streaming*

### Pause & Comment
![Pause & Comment](docs/screenshots/03-pause-comment.png)
*Pause the debate to inject your own feedback*

### Final Conclusion
![Final Conclusion](docs/screenshots/04-conclusion.png)
*Structured synthesis with risk assessment and next steps*

---

## ğŸ¤– The 16 Roles

The debate iterates through **16 specialized roles** in order. Each role can use any of the 16 available models, and if a model fails, the system automatically tries the next available model.

| # | Role | Icon | Purpose |
|---|------|------|---------|
| 1 | **Researcher** | ğŸŒ | Real-time web data, verifiable facts |
| 2 | **Critic** | ğŸ§  | Devil's advocate, find flaws |
| 3 | **Architect** | ğŸ’š | System design, technical implementation |
| 4 | **Risk Manager** | ğŸ¦™ | Identify what can go wrong |
| 5 | **Economist** | ğŸ’  | Financial viability, cost analysis |
| 6 | **Visionary** | ğŸ‘ï¸ | Disruptive ideas, think differently |
| 7 | **Engineer** | ğŸŸ¢ | Concrete implementation details |
| 8 | **Simplifier** | ğŸ”¸ | Cut through noise, clarify |
| 9 | **Validator** | ğŸ–¼ï¸ | Detect contradictions, verify consistency |
| 10 | **Strategist** | ğŸš€ | Macro vision, long-term planning |
| 11 | **Historian** | ğŸ® | Precedents, similar cases |
| 12 | **Optimizer** | â˜€ï¸ | Efficiency, continuous improvement |
| 13 | **Skeptic** | âš¡ | Demand proof, question everything |
| 14 | **Pragmatist** | ğŸ’™ | What actually works in practice |
| 15 | **Integrator** | ğŸ”º | Synthesize perspectives, seek consensus |
| 16 | **Provocateur** | ğŸ’§ | Uncomfortable questions, break assumptions |

### ğŸ”„ Resilient Model Pool

**16 models** rotate across roles. If one fails, the system tries the next:

| Model | Provider | Size | Type |
|-------|----------|------|------|
| Perplexity Sonar Reasoning Pro | Perplexity | N/A | Web Search |
| Qwen3 235B Thinking | Qwen | 235B | Free |
| Llama 3.3 70B Instruct | Meta | 70B | Free |
| Gemma 3 27B | Google | 27B | Free |
| Qwen3 VL 235B Thinking | Qwen | 235B | Free |
| Nemotron 3 Nano 30B | NVIDIA | 30B | Free |
| Trinity Mini | Arcee | 26B | Free |
| Nemotron Nano 12B VL | NVIDIA | 12B | Free |
| Step 3.5 Flash | StepFun | N/A | Free |
| GLM 4.5 Air | Z.ai | N/A | Free |
| Solar Pro 3 | Upstage | N/A | Free |
| Nemotron Nano 9B V2 | NVIDIA | 9B | Free |
| GPT-OSS 20B | OpenAI | 20B | Free |
| GPT-OSS 120B | OpenAI | 120B | Free |
| Trinity Large Preview | Arcee | N/A | Free |
| LFM 2.5 1.2B Thinking | Liquid | 1.2B | Free |

---

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx              # Main UI
â”‚   â”œâ”€â”€ globals.css
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ debate/
â”‚           â”œâ”€â”€ route.ts      # SSE streaming endpoint
â”‚           â””â”€â”€ conclude/
â”‚               â””â”€â”€ route.ts  # Conclusion synthesis endpoint
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatView.tsx          # Message feed with smart scroll
â”‚   â”œâ”€â”€ StatusBar.tsx         # Running state, pause/resume UI
â”‚   â”œâ”€â”€ ProposalForm.tsx      # Input form
â”‚   â””â”€â”€ ConclusionPanel.tsx   # Final synthesis display
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useDebateStream.ts    # SSE client + localStorage persistence
â””â”€â”€ lib/
    â”œâ”€â”€ models.ts             # Roles, models, and rotation logic
    â”œâ”€â”€ orchestrator.ts       # Resilient role-model orchestrator
    â”œâ”€â”€ prompts.ts            # Role-specific system prompts
    â”œâ”€â”€ perplexity.ts         # Perplexity API client
    â”œâ”€â”€ openrouter.ts         # OpenRouter API client
    â”œâ”€â”€ config.ts             # Token limits, settings
    â””â”€â”€ types.ts              # Shared TypeScript types
```

**Resilient Debate Flow:**
1. User submits a proposal
2. Server opens an SSE stream
3. Orchestrator iterates through **16 roles** sequentially
4. For each role:
   - Try models in rotation (starting from last successful model)
   - If a model fails (404, rate limit, API error), try the next model
   - If all models fail for a role, skip that turn
   - If a model succeeds, rotate to the next model for that role
5. Tokens stream back to the client in real time
6. Each agent sees the full conversation history compressed (last 4 messages verbatim, older ones summarized)
7. User can pause, inject a comment, and resume â€” agents continue with that context

**Why this works:**
- **No single point of failure** â€” if one model is down, others compensate
- **Fair distribution** â€” models rotate, so no model is overused
- **Zero downtime** â€” debates continue even during API outages
- **Cost optimization** â€” falls back to smaller/cheaper models when large ones fail

---

## ğŸš€ Getting Started

### Prerequisites

- Node.js 20+
- A [Perplexity API key](https://www.perplexity.ai/settings/api) (paid, ~$0.001/request)
- An [OpenRouter API key](https://openrouter.ai/settings/keys) (free tier â€” all 15 OpenRouter models cost $0)

### Installation

```bash
git clone https://github.com/ulrickpsp/conversational-ai.git
cd conversational-ai
npm install
```

### Environment Setup

```bash
cp .env.local.example .env.local
```

Edit `.env.local` and add your keys:

```env
PERPLEXITY_API_KEY=pplx-your-key-here
OPENROUTER_API_KEY=sk-or-v1-your-key-here
```

### Run

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000).

---

## ğŸ® Usage

1. **Enter a proposal** â€” a question, idea, or topic you want debated
2. **Choose a mode**: Conservative / Balanced / Aggressive
3. **Watch 16 agents** argue in sequence, each from their unique role
4. **Scroll freely** â€” auto-scroll pauses when you scroll up, resumes at the bottom
5. **Pause anytime** â€” click â¸ to pause, write a steering comment, then â–¶ï¸ Continue
6. **Stop & conclude** â€” click â¹ to generate a structured JSON conclusion
7. **Refresh safely** â€” F5 restores the full conversation from localStorage
8. **New session** â€” click ğŸ”„ to clear everything and start fresh

---

## âš™ï¸ Configuration

Key settings in `src/lib/config.ts`:

| Setting | Default | Description |
|---------|---------|-------------|
| `maxTokensPerplexity` | `400` | Max tokens per Perplexity turn |
| `maxTokensOpenRouter` | `500` | Max tokens per OpenRouter turn |

---

## ğŸ› ï¸ Tech Stack

- **[Next.js 16](https://nextjs.org/)** â€” App Router, Turbopack
- **[React 19](https://react.dev/)** â€” UI
- **[TypeScript 5](https://www.typescriptlang.org/)** â€” Type safety
- **[Tailwind CSS 4](https://tailwindcss.com/)** â€” Styling
- **[OpenAI SDK v6](https://github.com/openai/openai-node)** â€” Compatible interface for Perplexity + OpenRouter
- **Server-Sent Events** â€” Real-time token streaming
- **localStorage** â€” Client-side debate persistence

---

## ğŸ”’ Security

- API keys are stored server-side only in `.env.local`
- `.env.local` is gitignored â€” never committed
- Keys are never exposed to the browser
- All API calls happen in Next.js Route Handlers (server-side)

---

## ğŸ“„ License

MIT
